tiara {

    app-name = "TIARA"

    hadoop-default-fs = "hdfs://localhost:9000"
    date-time-format-to-display = "yyyy-MM-dd HH:mm:ss"

    decahose-processor{

        historical{
            enabled = true
            data-path = ${tiara.hadoop-default-fs}"data/rawTweets/*"
        }

        decahose-dir = ${tiara.hadoop-default-fs}"/tiara/decahose/streaming"
        daily-en-tweets-dir = ${tiara.hadoop-default-fs}"/tiara/en"
        tokens-dir = ${tiara.hadoop-default-fs}"/tiara/toks"
        debug-dir = ${tiara.hadoop-default-fs}"/tiara/debug"

        post-date-col-name = "postedDate"
        tokens-column = "toks"

        update-redis-counters = false
        redis-server = "spark11"

        tweet-schema-json = "decahose-large.json"

        writing-mode-string = "_WRITING_"

        poll-decahose-actor{
            timezone = "PST"

            //Build file name on Bluemix server
            fileNameFormatForURL = "yyyy/MM/dd/yyyy_MM_dd_HH_mm"
            fileNameFormat = "yyyy_MM_dd_HH_mm"
            fileNameExtensionJson = "activity.json.gz"
            //files older than Jun 2015
            fileNameExtensionGson = "activity.gson.gz"

            //Bluemix Credentials
            user = "#########"
            password = "###########"
            //Bluemix URL
            hostname = "https://cde-archive.services.dal.bluemix.net/"

            // Time in seconds when the actor scheduled is going to start its process
            startDownloadingAfter = 10
            // scheduler time interval in seconds
            timeInterval = 60
        }

        spark{
            sql-shuffle-partitions = 5
            UI-port = "4040"
            executor-memory = "1g"
            cores-max = 4
            executor-cores = 1

            //Batch time in seconds
            streaming-batch-time = 60
            delete-file-after-processed = true
        }
    }

    word-2-vec{

        historical{
            enabled = true
            start-date = "2016-01-01"
            end-date = "2016-01-31"
        }

        path-to-daily-tweets = ${tiara.decahose-processor.tokens-dir}
        path-to-daily-models = ${tiara.hadoop-default-fs}"/models/daily"
        col-name-tweet-txt = ${tiara.decahose-processor.tokens-column}
        prefix-tokens-folder-daily = ${tiara.decahose-processor.post-date-col-name}"="
        date-format = "yyyy-MM-dd"

        folder-name-model = "word2VecModel"
        folder-name-word-count = "frequencyAnalysis"
        token-file-name = "newModel.txt"

        start-scheduler-after = 0
        generate-model-timeinterval = 400

        parameters{
            partition-number = 6
            iterations-number = 6
            min-word-count = 10
            vector-size = 100
        }

        spark{
            sql-shuffle-partitions = 5
            UI-port = "4041"
            executor-memory = "1g"
            cores-max = 4
            executor-cores = 1
        }
    }

    rest-api{

        bind-port = 16666
        bind-ip = "0.0.0.0"

        path-to-daily-models = ${tiara.word-2-vec.path-to-daily-models}
        token-file-name = ${tiara.word-2-vec.token-file-name}
        folder-name-model = ${tiara.word-2-vec.folder-name-model}
        folder-name-word-count = ${tiara.word-2-vec.folder-name-word-count}

        start-scheduler-after = 0
        // Every 10min
        check-for-new-model-interval = 600

        spark{
            sql-shuffle-partitions = 5
            UI-port = "4042"
            executor-memory = "1g"
            cores-max = 4
            executor-cores = 1
        }
    }
}
